{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996f5c2d-4222-4387-98d0-d9e3425031c0",
   "metadata": {},
   "source": [
    "#### Part I Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50305838-8894-4287-8384-eb5a78caecb9",
   "metadata": {},
   "source": [
    "####  Required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a8cea5-cdf8-46c6-a672-dc3fc0ede1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59959e38-c534-4a18-a7bb-c200fe222f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in d:\\x-20a\\anaconda3\\lib\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "# Importing an ipynb file from another ipynb file\n",
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d3e0ae-8a5e-4cce-881a-bdfb94860378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in d:\\x-20a\\anaconda3\\lib\\site-packages (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "# Importing functions from another jupyter notebook\n",
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7322bf-9acb-4f2b-b8fc-c94746614156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting global variables...\n"
     ]
    }
   ],
   "source": [
    "%run GlobalConfig.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40c9795-1795-482e-9499-cca769792ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Loader notebook\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import loader_nb\n",
    "import model_selection_helper_nb\n",
    "\n",
    "loader = loader_nb.UrlDatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e64788-e538-4c21-a48f-f17a283dc1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_data in module loader_nb:\n",
      "\n",
      "load_data(url='https://raw.githubusercontent.com/quickheaven/scs-3253-machine-learning/master/datasets/ISCX-URL2016_All.csv') method of loader_nb.UrlDatasetLoader instance\n",
      "    (string) --> dataframe\n",
      "    \n",
      "    This function returns the dataframe of maliciours url.    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    url: By default, it fetch the data from github otherwise a local path or url can be provided so the data can be loaded faster.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(loader.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2df0757-043c-4cdd-af9c-3c359f1d3022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method prepare_data in module loader_nb:\n",
      "\n",
      "prepare_data(data, fill_na=True, feature_selection=True) method of loader_nb.UrlDatasetLoader instance\n",
      "    (DataFrame, boolean, boolean) --> X and y of the dataframe.\n",
      "    \n",
      "    This function returns the X and y of the malicious url dataframe.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fill_na : True to fill the na records with mean values otherwise drop the features.\n",
      "    \n",
      "    feature_selection : True to remove one or more features that have a correlation higher than 0.9 othewise do not perform that kind of feature selection.\n",
      "    \n",
      "    anomaly_detection: True to remove outliers using unsupervised anomaly detection via Isolation Forest, otherwise no anomaly detection will be performed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(loader.prepare_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f63a371-e6f7-49ad-a089-aa5bededaebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loader.load_data(DATASET_LOCAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ea4c8e9-4c73-4a8d-955f-e7d17f05bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_tune_models( data, fill_na=True, feature_selection=True, anomaly_detection=True):\n",
    "    print('train_and_tune_models fill_na:', str(fill_na), 'feature_selection:', str(feature_selection), 'anomaly_detection:' + str(anomaly_detection))\n",
    "    \n",
    "    X, y = loader.prepare_data(data.copy(), fill_na=fill_na, feature_selection=feature_selection)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = loader.train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, anomaly_detection=anomaly_detection)\n",
    "    \n",
    "    models_to_train = loader.get_models_to_train()\n",
    "    parameters_to_train = loader.get_parameters_to_train(True)\n",
    "    \n",
    "    model_selection_helper = model_selection_helper_nb.ModelSelectionHelper(models_to_train, parameters_to_train)\n",
    "    \n",
    "    model_selection_helper.fit(X_train, y_train, cv=3, scoring='accuracy', verbose=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20fbc4-a9dc-4134-86a9-de29705ad056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "789c5803-b834-4a77-8e36-ea8f7fa60be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_and_tune_models fill_na:  True feature_selection:  True anomaly_detection: True\n",
      "The X_train, y_train shape\n",
      "(25694, 51)\n",
      "(25694,)\n",
      "The shape after unsupervised anomaly detection:\n",
      "(25437, 51)\n",
      "(25437,)\n",
      "The X_test, y_test shape\n",
      "(11013, 51)\n",
      "(11013,)\n",
      "The shape after unsupervised anomaly detection:\n",
      "(10902, 51)\n",
      "(10902,)\n",
      "init model selection helper notebook\n",
      "---------------------------------------------------------------------------\n",
      "KNeighborsClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "KNeighborsClassifier :  {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "0.9583284192318277\n",
      "---------------------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "DecisionTreeClassifier :  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "0.8888626803475254\n",
      "---------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "RandomForestClassifier :  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.9347407320045603\n",
      "---------------------------------------------------------------------------\n",
      "GradientBoostingClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "GradientBoostingClassifier :  {'learning_rate': 0.1, 'max_depth': 9, 'subsample': 0.7}\n",
      "0.9763336871486418\n",
      "---------------------------------------------------------------------------\n",
      "LogisticRegression\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "LogisticRegression :  {'C': 100, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.814286275897315\n",
      "---------------------------------------------------------------------------\n",
      "AdaBoostClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "AdaBoostClassifier :  {'algorithm': 'SAMME', 'learning_rate': 1.0}\n",
      "0.6979596650548414\n",
      "Wall time: 5min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TRUE TRUE TRUE\n",
    "train_and_tune_models(df, fill_na=True, feature_selection=True, anomaly_detection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "684c5f7d-6b21-4309-8f39-fc9893b50c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_and_tune_models fill_na:  True feature_selection:  True anomaly_detection: False\n",
      "The X_train, y_train shape\n",
      "(25694, 51)\n",
      "(25694,)\n",
      "The X_test, y_test shape\n",
      "(11013, 51)\n",
      "(11013,)\n",
      "init model selection helper notebook\n",
      "---------------------------------------------------------------------------\n",
      "KNeighborsClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "KNeighborsClassifier :  {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "0.9586284476967669\n",
      "---------------------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "DecisionTreeClassifier :  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "0.8911807655627547\n",
      "---------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "RandomForestClassifier :  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.9346929439126156\n",
      "---------------------------------------------------------------------------\n",
      "GradientBoostingClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "GradientBoostingClassifier :  {'learning_rate': 0.1, 'max_depth': 9, 'subsample': 0.7}\n",
      "0.9764924860026253\n",
      "---------------------------------------------------------------------------\n",
      "LogisticRegression\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "LogisticRegression :  {'C': 100, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.8137698238388947\n",
      "---------------------------------------------------------------------------\n",
      "AdaBoostClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "AdaBoostClassifier :  {'algorithm': 'SAMME', 'learning_rate': 1.0}\n",
      "0.6958045140061907\n",
      "Wall time: 6min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TRUE TRUE FALSE\n",
    "train_and_tune_models(df, fill_na=True, feature_selection=True, anomaly_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c164608-3176-40f1-8500-2590193fa02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TRUE FALSE FALSE\n",
    "# train_and_tune_models(df, fill_na=True, feature_selection=False, anomaly_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "830d6971-58bc-419d-9242-34499e6cbee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FALSE FALSE FALSE\n",
    "# train_and_tune_models(df, fill_na=False, feature_selection=False, anomaly_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7720271f-d21d-4d18-b8c0-e53728eff384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FALSE TRUE TRUE\n",
    "# train_and_tune_models(df, fill_na=False, feature_selection=True, anomaly_detection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "831dba15-b6a1-4037-a190-69e68b82e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FALSE FALSE TRUE\n",
    "# train_and_tune_models(df, fill_na=False, feature_selection=False, anomaly_detection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f3790-c155-40a8-8df9-f11f610f5f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247456a7-3f89-4c53-adbd-edc13f9dfac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df4773-1195-4b7c-b2c6-2993112cfbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee168627-285c-4680-8e60-e390f5ca0501",
   "metadata": {},
   "source": [
    "#### Experiment: Find which data preparation setup return better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d3b47b1-6318-4ed4-b341-0d0026077c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def eval_data_prep(X, y, anomaly_detection=False): \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "    \n",
    "    #if (anomaly_detection==True):\n",
    "        #iforest = IsolationForest(contamination=0.01, random_state=RANDOM_STATE).fit(X_train)\n",
    "\n",
    "        #y_pred_iforest = iforest.predict(X_train)\n",
    "\n",
    "        #X_train, y_train = X_train[(y_pred_iforest != -1)], y_train[(y_pred_iforest != -1)]        \n",
    "\n",
    "    #lr_clf = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "\n",
    "    #lr_clf.fit(X_train, y_train)\n",
    "\n",
    "    #y_pred_lr = lr_clf.predict(X_train)\n",
    "\n",
    "    #return accuracy_score(y_train, y_pred_lr)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b15e00c-4c9d-41b3-8835-6eee2edff5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8918a37c-da9e-4c32-94d8-e484ca97c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36707, 51)\n",
      "(36707,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df) # default\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "216841a6-ea7d-47b5-b3ef-4832b42504ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36707, 78)\n",
      "(36707,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df, fill_na=True, feature_selection=False)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60590329-e59d-42ff-8f1e-0cb8eb76e650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18982, 49)\n",
      "(18982,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df, fill_na=False, feature_selection=True)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f524d7e-3300-46fa-b2e6-02cf037bda18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18982, 78)\n",
      "(18982,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df, fill_na=False, feature_selection=False)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38316319-bea8-4bf3-b4b1-4fc062d61bf0",
   "metadata": {},
   "source": [
    "#### Experiment: Unsupervised Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2128d399-4292-407c-9060-4e481fc54a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36707, 51)\n",
      "(36707,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df) # default\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y, anomaly_detection=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9cde3ea-342a-4c9b-8f07-79353f1ac952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36707, 78)\n",
      "(36707,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df, fill_na=True, feature_selection=False)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y, anomaly_detection=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b68a493-7fd0-41ff-9fc7-fe1430ec9ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18982, 49)\n",
      "(18982,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df, fill_na=False, feature_selection=True)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y, anomaly_detection=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cadd345-6782-436a-a92c-66ee94d8dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18982, 78)\n",
      "(18982,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_data(url=DATASET_LOCAL_PATH)\n",
    "X, y = loader.prepare_data(df, fill_na=False, feature_selection=False)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(eval_data_prep(X, y, anomaly_detection=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931bd333-5e76-4562-9644-10add110eac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f7e94-b304-4eea-8455-770fef165e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
