{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c33f88cb-0b73-4d06-86dc-2f0e3d58fbad",
   "metadata": {},
   "source": [
    "## Part II - Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc35e9c-91a1-444c-89da-2c906006f894",
   "metadata": {},
   "source": [
    "####  Required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d36cf-a735-4f2e-a51e-6d1bfd353ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060745a3-e2da-4470-b586-493653a7c92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in d:\\x-20a\\anaconda3\\lib\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "# Importing an ipynb file from another ipynb file\n",
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271481f5-28fc-4d75-99ea-cef8495b566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in d:\\x-20a\\anaconda3\\lib\\site-packages (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "# Importing functions from another jupyter notebook\n",
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7230269a-0647-4591-9ee7-ee2d327a2ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting global variables...\n"
     ]
    }
   ],
   "source": [
    "%run GlobalConfig.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc3556-0fd2-4c0f-a0d4-ca16fcd3e2c6",
   "metadata": {},
   "source": [
    "#### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54de16d-8913-4235-b783-cdd12268acea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Loader notebook\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import loader_nb\n",
    "import model_selection_helper_nb\n",
    "\n",
    "loader = loader_nb.UrlDatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12311ca-aae0-46bb-baf2-48fa6be0585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327939ef-1540-4b46-a30f-29510be336af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loader.prepare_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adaf8e-298a-4a66-b3f7-4cff09fb6415",
   "metadata": {},
   "source": [
    "#### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d78c94c-f72e-4dba-bdea-2d9c5445df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split    \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5b6c1-1274-43a1-a545-f93b2e2b10af",
   "metadata": {},
   "source": [
    "#### Train and Optimize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "313137e7-f6d8-4396-be09-493d5ff2a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# assignment number 7 classifiers\n",
    "def get_models(): \n",
    "    models = dict()\n",
    "    models['LogisticRegression'] = LogisticRegression(random_state=RANDOM_STATE, max_iter=MAX_ITER)\n",
    "    models['AdaBoostClassifier'] = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "    models['ExtraTreesClassifier'] = ExtraTreesClassifier(random_state=RANDOM_STATE)\n",
    "    models['GradientBoostingClassifier'] = GradientBoostingClassifier(random_state=RANDOM_STATE)        \n",
    "    models['RandomForestClassifier'] = RandomForestClassifier(random_state=RANDOM_STATE, max_depth=MAX_DEPTH)\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "215baf36-5ef2-49b2-9993-b6110843977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(): \n",
    "    \n",
    "    params_log = dict()\n",
    "    params_log['solver'] = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    #params_log['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "    #params_log['penalty'] = ['l2']\n",
    "    #params_log['C'] = [100, 10, 1.0, 0.1, 0.01]\n",
    "       \n",
    "    params_ada = dict()\n",
    "    params_ada['learning_rate'] = [0.01, 0.1, 1.0]\n",
    "    params_ada['algorithm'] = ['SAMME', 'SAMME.R']\n",
    "    \n",
    "    params_ext = dict()\n",
    "    params_ext['criterion'] = ['gini', 'entropy']\n",
    "    params_ext['max_depth'] = [2, 3, 4]         # default: 3\n",
    "    #params_ext['max_leaf_nodes'] = [10, 20, 30]\n",
    "    #params_ext['min_samples_leaf'] = [1, 3, 4]  # default: 1\n",
    "    #params_ext['min_samples_split'] = [2, 3, 4] # default: 2\n",
    "    \n",
    "    params_gra = dict()\n",
    "    params_gra['criterion'] = ['friedman_mse']\n",
    "    #params_gra['max_depth'] = [2, 3, 4]         # default: 3\n",
    "    #params_gra['max_leaf_nodes'] = [10, 20, 30]\n",
    "    #params_gra['min_samples_leaf'] = [1, 3, 4]  # default: 1\n",
    "    #params_gra['min_samples_split'] = [2, 3, 4] # default: 2\n",
    "        \n",
    "    params_ran = dict()\n",
    "    params_ran['criterion'] = ['gini', 'entropy']\n",
    "    #params_ran['max_depth'] = [2, 3, 4]         # default: 3\n",
    "    #params_ran['max_leaf_nodes'] = [10, 20, 30]\n",
    "    #params_ran['min_samples_leaf'] = [1, 3, 4]  # default: 1\n",
    "    #params_ran['min_samples_split'] = [2, 3, 4] # default: 2\n",
    "        \n",
    "    params = dict()\n",
    "    params['LogisticRegression'] = params_log\n",
    "    params['AdaBoostClassifier'] = params_ada\n",
    "    params['ExtraTreesClassifier'] = params_ext\n",
    "    params['GradientBoostingClassifier'] = params_gra\n",
    "    params['RandomForestClassifier'] = params_ran    \n",
    "    \n",
    "    return params    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f7db9d-ccf4-4a11-9492-d950538516a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = get_models()\n",
    "parameters_to_train = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "120445d1-516f-4b22-ba5b-3a5da125b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_helper = model_selection_helper_nb.ModelSelectionHelper(models_to_train, parameters_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22cf3f0-9a51-44ab-84ce-65ed38066f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "LogisticRegression\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "LogisticRegression :  {'solver': 'sag'}\n",
      "0.7650814775672549\n",
      "---------------------------------------------------------------------------\n",
      "AdaBoostClassifier\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "AdaBoostClassifier :  {'algorithm': 'SAMME', 'learning_rate': 1.0}\n",
      "0.6958045140061907\n",
      "---------------------------------------------------------------------------\n",
      "ExtraTreesClassifier\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "ExtraTreesClassifier :  {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.7050673209120863\n",
      "---------------------------------------------------------------------------\n",
      "GradientBoostingClassifier\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "GradientBoostingClassifier :  {'criterion': 'friedman_mse'}\n",
      "0.9379622532821563\n",
      "---------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "RandomForestClassifier :  {'criterion': 'gini'}\n",
      "0.9701486348816312\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_selection_helper.fit(X_train, y_train, scoring='accuracy', verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ff988-d61f-4437-974b-f02f4bc9e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b14378-fefc-4510-834b-d04e70e18ea6",
   "metadata": {},
   "source": [
    "#### Run the models with test data using the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3578fe8a-8f48-4948-bd3e-ed82ace2e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy_score:  0.7594660855352765\n",
      "LogisticRegression f1_score:  0.7561260115308194\n",
      "AdaBoostClassifier accuracy_score:  0.6874602742213748\n",
      "AdaBoostClassifier f1_score:  0.6814893406164179\n",
      "ExtraTreesClassifier accuracy_score:  0.6997185144828839\n",
      "ExtraTreesClassifier f1_score:  0.6899379042982596\n",
      "GradientBoostingClassifier accuracy_score:  0.9496958140379551\n",
      "GradientBoostingClassifier f1_score:  0.9497825725059457\n",
      "RandomForestClassifier accuracy_score:  1.0\n",
      "RandomForestClassifier f1_score:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for key in models_to_train.keys():\n",
    "    \n",
    "    model = model_selection_helper.get_model_best_estimator(key)\n",
    "    \n",
    "    model.fit(X_test, y_test)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "        \n",
    "    print(key, 'accuracy_score: ', accuracy_score(y_test, y_pred))\n",
    "    print(key, 'f1_score: ', f1_score(y_test, y_pred, average='weighted'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ebc65-4d59-4016-b7b9-4c0f069a26f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f38d8-36c3-4205-aa04-401d0712a656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
